{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99449de6-85e8-41e9-b4ea-7e50866d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3eea338-d373-4d32-8815-54ba0a156e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/majotagliaferro/Documents/TPRN/skin-dataset-classification-main/mlruns/249710420298442039', creation_time=1763846127725, experiment_id='249710420298442039', last_update_time=1763846127725, lifecycle_stage='active', name='MLP_Clasificador_Imagenes', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MLP_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d21eeefb-bc83-4931-acbc-65ca26d10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573d2f49-abfd-444a-a947-712c1737eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para loguear una figura matplotlib en TensorBoard\n",
    "def plot_to_tensorboard(fig, writer, tag, step):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "    writer.add_image(tag, image, global_step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4901b00e-6c31-4af2-ab6d-1cc383687d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para matriz de confusi√≥n y clasificaci√≥n\n",
    "def log_classification_report(model, loader, writer, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.label_encoder.classes_)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=train_dataset.label_encoder.classes_)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # Tambi√©n loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d6564e0-f970-461a-8ab4-5d19e0d55040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear directorio de logs\n",
    "log_dir = \"runs/mlp_experimento_1\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41919c3b-76d8-4eb0-810a-62ce743752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "          # SOLO carpetas v√°lidas\n",
    "        class_names = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))\n",
    "        ])\n",
    "\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "        for cls in class_names:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "\n",
    "            # Evitar errores si la carpeta est√° corrupta\n",
    "            try:\n",
    "                files = os.listdir(cls_dir)\n",
    "            except NotADirectoryError:\n",
    "                continue\n",
    "\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, fname))\n",
    "                    self.labels.append(cls)\n",
    "\n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bc0d2e4-319e-4f95-a59b-565182681864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32743888-c68f-4a1a-a5e0-afe766b91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a707a13e-87cc-4c2b-89fd-b83ff1fd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e18375e-9fb1-4084-8338-302ca99f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a9d4d33-e68d-4ccb-8b0e-f18deabc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=64*64*3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Flatten(),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da9b8088-283f-4549-8c86-2fec28283e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validaci√≥n\n",
    "def evaluate(model, loader, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, val_loader, writer, step=epoch, prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear im√°genes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d5e76-139b-43b0-a5f0-a781b0a22463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:15<00:00,  1.46it/s]\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 2.6753, Accuracy: 27.55%\n",
      "  Val   Loss: 1.5801, Accuracy: 41.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 1.5808, Accuracy: 43.76%\n",
      "  Val   Loss: 1.5909, Accuracy: 48.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.88it/s]\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 1.5297, Accuracy: 46.34%\n",
      "  Val   Loss: 1.3934, Accuracy: 50.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:12<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 1.2291, Accuracy: 52.51%\n",
      "  Val   Loss: 1.2996, Accuracy: 50.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:13<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 1.1028, Accuracy: 57.96%\n",
      "  Val   Loss: 1.2128, Accuracy: 52.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 1.1721, Accuracy: 56.67%\n",
      "  Val   Loss: 1.3233, Accuracy: 49.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:12<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 1.1662, Accuracy: 57.25%\n",
      "  Val   Loss: 1.2817, Accuracy: 58.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 0.9747, Accuracy: 64.71%\n",
      "  Val   Loss: 1.2472, Accuracy: 56.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 0.9035, Accuracy: 66.43%\n",
      "  Val   Loss: 1.1960, Accuracy: 65.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.91it/s]\n",
      "2025/11/24 19:19:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 0.8634, Accuracy: 65.28%\n",
      "  Val   Loss: 1.2696, Accuracy: 55.25%\n",
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/24 19:19:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# # Loop de entrenamiento\n",
    "# n_epochs = 10\n",
    "# with mlflow.start_run():\n",
    "#     # Log hiperpar√°metros\n",
    "#     mlflow.log_params({\n",
    "#         \"model\": \"MLPClassifier\",\n",
    "#         \"input_size\": 64*64*3,\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"lr\": 1e-3,\n",
    "#         \"epochs\": n_epochs,\n",
    "#         \"optimizer\": \"Adam\",\n",
    "#         \"loss_fn\": \"CrossEntropyLoss\",\n",
    "#         \"train_dir\": train_dir,\n",
    "#         \"val_dir\": val_dir,\n",
    "#     })\n",
    "#     for epoch in range(n_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct, total = 0, 0\n",
    "    \n",
    "#         for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "    \n",
    "#             running_loss += loss.item()\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "   \n",
    "#         for name, param in model.named_parameters():\n",
    "#             writer.add_histogram(name, param, epoch)\n",
    "    \n",
    "#         train_loss = running_loss / len(train_loader)\n",
    "#         train_acc = 100.0 * correct / total\n",
    "#         val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "    \n",
    "#         print(f\"Epoch {epoch+1}:\")\n",
    "#         print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "#         print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "#         writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "#         writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "    \n",
    "#         # Log en MLflow\n",
    "#         mlflow.log_metrics({\n",
    "#             \"train_loss\": train_loss,\n",
    "#             \"train_accuracy\": train_acc,\n",
    "#             \"val_loss\": val_loss,\n",
    "#             \"val_accuracy\": val_acc\n",
    "#         }, step=epoch)\n",
    "#         # Guardar modelo\n",
    "#     torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "#     print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "#     mlflow.log_artifact(\"mlp_model.pth\")\n",
    "#     mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "#     print(\"Modelo guardado como 'mlp_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c9fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå TensorBoard run directory: runs/mlp_experimento_1_20251124_193642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:15<00:00,  1.44it/s]\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 2.7122, Accuracy: 30.13%\n",
      "  Val   Loss: 1.9659, Accuracy: 34.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:18<00:00,  1.22it/s]\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 1.6931, Accuracy: 44.19%\n",
      "  Val   Loss: 1.5363, Accuracy: 49.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:14<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 1.4428, Accuracy: 49.21%\n",
      "  Val   Loss: 1.5444, Accuracy: 41.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:13<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 1.2270, Accuracy: 54.23%\n",
      "  Val   Loss: 1.4956, Accuracy: 51.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 1.1224, Accuracy: 57.10%\n",
      "  Val   Loss: 1.2729, Accuracy: 49.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:12<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 1.0425, Accuracy: 58.68%\n",
      "  Val   Loss: 1.2529, Accuracy: 53.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 1.0729, Accuracy: 62.84%\n",
      "  Val   Loss: 1.5472, Accuracy: 50.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 1.1158, Accuracy: 57.39%\n",
      "  Val   Loss: 1.6508, Accuracy: 45.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 1.0285, Accuracy: 60.98%\n",
      "  Val   Loss: 1.5037, Accuracy: 56.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:11<00:00,  1.92it/s]\n",
      "2025/11/24 19:39:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 0.9587, Accuracy: 64.28%\n",
      "  Val   Loss: 1.4074, Accuracy: 51.93%\n",
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/24 19:40:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Entrenamiento finalizado correctamente.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# CREAR NOMBRE √öNICO PARA EL RUN DE TENSORBOARD\n",
    "# -----------------------------------------------------------\n",
    "run_name = f\"mlp_experimento_1_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "print(f\"üìå TensorBoard run directory: runs/{run_name}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# LOOP DE ENTRENAMIENTO\n",
    "# -----------------------------------------------------------\n",
    "n_epochs = 10\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log hiperpar√°metros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"MLPClassifier\",\n",
    "        \"input_size\": 64*64*3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "        \"tensorboard_run\": run_name\n",
    "    })\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        # Histograma de par√°metros\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f\"weights/{name}\", param, epoch)\n",
    "\n",
    "        # M√©tricas\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Val\n",
    "        val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        # Log a TensorBoard\n",
    "        writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "        writer.add_scalar(\"val/loss\", val_loss, epoch)\n",
    "        writer.add_scalar(\"val/accuracy\", val_acc, epoch)\n",
    "\n",
    "        # Log a MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc\n",
    "        }, step=epoch)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # GUARDAR MODELO\n",
    "    # -------------------------------------------------------\n",
    "    torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "    print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "\n",
    "    mlflow.log_artifact(\"mlp_model.pth\")\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "\n",
    "print(\"üèÅ Entrenamiento finalizado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "551ce1c4-58b3-4abf-8eb7-107b760ba69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/{tpredes}/lib/python3.12/site-packages/tensorboard/default.py:30: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.20.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs/mlp_experimento_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP Redes Limpio",
   "language": "python",
   "name": "tpredes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
